# @package _global_
defaults:
  - _default
model:
  spike_context_integration: "in_context"
train:
  autoscale_batch_size: true
  effective_batch_size: 1028
