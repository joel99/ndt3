# @package _global_
defaults:
  - _default
model:
  task:
    context_prompt_time_thresh: 100
train:
  batch_size: 8 # Will use 80G