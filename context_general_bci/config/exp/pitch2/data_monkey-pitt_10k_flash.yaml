# @package _global_

defaults:
  - _default
model:
  arch: Architecture.flash_ndt
  lr_decay_steps: 10000
  transformer:
    initializer_range: 0.0 # Match torch native empirical init std, though they don't use Gaussian
dataset:
  datasets:
  # All cropped trialized data, but ~100K trials.
  - churchland.*
  - gallego.*
  - dyer_co.*
  - miller.*
  - odoherty_rtt.*
  - delay.*
  - pitt_broad.*
train:
  # batch_size: 24 # 40G
  batch_size: 48 # 80G
  # batch_size: 32 # 40G OOMs
  # batch_size: 64 # 80G
  patience: 50
  # effective_batch_size: 2048
  effective_batch_size: 8192
# load_from_id: data_monkey-pitt-xfhobr8j # Loaded at around 2.5K steps, 40 epochs. Picked up because 6K doesn't look like enough.