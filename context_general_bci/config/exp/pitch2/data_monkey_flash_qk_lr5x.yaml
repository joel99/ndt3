# @package _global_

defaults:
  - _default
model:
  lr_init: 2.5e-3
  arch: Architecture.flash_ndt
  transformer:
    # use_biases: False
    # learnable_norm: False
    qk_normalization: True
    initializer_range: 0.0 # Match torch native empirical init std, though they don't use Gaussian
dataset:
  datasets:
  # All cropped trialized data, but ~100K trials.
  - churchland.*
  - gallego.*
  - dyer_co.*
  - miller.*
  - odoherty_rtt.*
  - delay.*
train:
  batch_size: 24 # 40G
  patience: 50
  # effective_batch_size: 2048
  effective_batch_size: 8192