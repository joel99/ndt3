# @package _global_

defaults:
  - _default
model:
  arch: Architecture.flash_ndt
  transformer:
    activation: swiglu
    # rotary_position: True
    # use_biases: False
    # learnable_norm: False
dataset:
  datasets:
  # All cropped trialized data, but ~100K trials.
  - churchland.*
  - gallego.*
  - dyer_co.*
  - miller.*
  - odoherty_rtt.*
  - delay.*
train:
  batch_size: 24 # 40G
  patience: 50
  # effective_batch_size: 2048
  effective_batch_size: 8192
